{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "29b0ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import all_estimators\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b63445",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "6a46cdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>...</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.075952</td>\n",
       "      <td>0.012840</td>\n",
       "      <td>0.045702</td>\n",
       "      <td>0.046137</td>\n",
       "      <td>0.105332</td>\n",
       "      <td>0.015669</td>\n",
       "      <td>0.019151</td>\n",
       "      <td>0.043743</td>\n",
       "      <td>0.073993</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077693</td>\n",
       "      <td>0.061371</td>\n",
       "      <td>0.080522</td>\n",
       "      <td>0.025898</td>\n",
       "      <td>0.009793</td>\n",
       "      <td>0.014146</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.020022</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.084178</td>\n",
       "      <td>0.019912</td>\n",
       "      <td>0.030404</td>\n",
       "      <td>0.038870</td>\n",
       "      <td>0.136998</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.031239</td>\n",
       "      <td>0.027423</td>\n",
       "      <td>0.075355</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090140</td>\n",
       "      <td>0.071659</td>\n",
       "      <td>0.077739</td>\n",
       "      <td>0.030643</td>\n",
       "      <td>0.013712</td>\n",
       "      <td>0.013950</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.010731</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.071646</td>\n",
       "      <td>0.012172</td>\n",
       "      <td>0.045643</td>\n",
       "      <td>0.032642</td>\n",
       "      <td>0.120055</td>\n",
       "      <td>0.014661</td>\n",
       "      <td>0.025173</td>\n",
       "      <td>0.023513</td>\n",
       "      <td>0.094606</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053942</td>\n",
       "      <td>0.087967</td>\n",
       "      <td>0.081051</td>\n",
       "      <td>0.029046</td>\n",
       "      <td>0.018811</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.017981</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072210</td>\n",
       "      <td>0.027715</td>\n",
       "      <td>0.029977</td>\n",
       "      <td>0.039593</td>\n",
       "      <td>0.121041</td>\n",
       "      <td>0.016780</td>\n",
       "      <td>0.023567</td>\n",
       "      <td>0.059012</td>\n",
       "      <td>0.065234</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059201</td>\n",
       "      <td>0.073341</td>\n",
       "      <td>0.093703</td>\n",
       "      <td>0.024321</td>\n",
       "      <td>0.005090</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.006033</td>\n",
       "      <td>0.017534</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073806</td>\n",
       "      <td>0.020368</td>\n",
       "      <td>0.031099</td>\n",
       "      <td>0.039641</td>\n",
       "      <td>0.141261</td>\n",
       "      <td>0.020368</td>\n",
       "      <td>0.020368</td>\n",
       "      <td>0.056943</td>\n",
       "      <td>0.065046</td>\n",
       "      <td>0.003285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072492</td>\n",
       "      <td>0.059571</td>\n",
       "      <td>0.095488</td>\n",
       "      <td>0.024967</td>\n",
       "      <td>0.010731</td>\n",
       "      <td>0.023872</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>0.014893</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.077913</td>\n",
       "      <td>0.014919</td>\n",
       "      <td>0.035749</td>\n",
       "      <td>0.044830</td>\n",
       "      <td>0.149735</td>\n",
       "      <td>0.011784</td>\n",
       "      <td>0.011496</td>\n",
       "      <td>0.012613</td>\n",
       "      <td>0.072003</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074741</td>\n",
       "      <td>0.082093</td>\n",
       "      <td>0.070561</td>\n",
       "      <td>0.054452</td>\n",
       "      <td>0.010631</td>\n",
       "      <td>0.004541</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>0.005334</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.072717</td>\n",
       "      <td>0.013065</td>\n",
       "      <td>0.035412</td>\n",
       "      <td>0.044990</td>\n",
       "      <td>0.150754</td>\n",
       "      <td>0.010523</td>\n",
       "      <td>0.010582</td>\n",
       "      <td>0.011528</td>\n",
       "      <td>0.071416</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076914</td>\n",
       "      <td>0.078333</td>\n",
       "      <td>0.065681</td>\n",
       "      <td>0.050902</td>\n",
       "      <td>0.012711</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.072599</td>\n",
       "      <td>0.015761</td>\n",
       "      <td>0.039836</td>\n",
       "      <td>0.051129</td>\n",
       "      <td>0.157111</td>\n",
       "      <td>0.013031</td>\n",
       "      <td>0.013527</td>\n",
       "      <td>0.014396</td>\n",
       "      <td>0.085629</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082030</td>\n",
       "      <td>0.066518</td>\n",
       "      <td>0.061057</td>\n",
       "      <td>0.042690</td>\n",
       "      <td>0.015140</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.004964</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.011501</td>\n",
       "      <td>0.035283</td>\n",
       "      <td>0.051852</td>\n",
       "      <td>0.143275</td>\n",
       "      <td>0.012086</td>\n",
       "      <td>0.020078</td>\n",
       "      <td>0.019493</td>\n",
       "      <td>0.089864</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.072320</td>\n",
       "      <td>0.063353</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>0.014035</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.003314</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.078738</td>\n",
       "      <td>0.010451</td>\n",
       "      <td>0.037253</td>\n",
       "      <td>0.053283</td>\n",
       "      <td>0.150487</td>\n",
       "      <td>0.016222</td>\n",
       "      <td>0.010708</td>\n",
       "      <td>0.015517</td>\n",
       "      <td>0.069377</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075083</td>\n",
       "      <td>0.071621</td>\n",
       "      <td>0.077584</td>\n",
       "      <td>0.053475</td>\n",
       "      <td>0.014299</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.126059</td>\n",
       "      <td>0.032387</td>\n",
       "      <td>0.014449</td>\n",
       "      <td>0.034380</td>\n",
       "      <td>0.096662</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>0.059791</td>\n",
       "      <td>0.013951</td>\n",
       "      <td>0.104634</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076731</td>\n",
       "      <td>0.069258</td>\n",
       "      <td>0.046836</td>\n",
       "      <td>0.042352</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.006477</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.009467</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.147555</td>\n",
       "      <td>0.024698</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>0.039441</td>\n",
       "      <td>0.093372</td>\n",
       "      <td>0.011089</td>\n",
       "      <td>0.033896</td>\n",
       "      <td>0.018523</td>\n",
       "      <td>0.100302</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046623</td>\n",
       "      <td>0.081401</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.040575</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.005040</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>0.013609</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.177360</td>\n",
       "      <td>0.023339</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.038741</td>\n",
       "      <td>0.083651</td>\n",
       "      <td>0.012691</td>\n",
       "      <td>0.049585</td>\n",
       "      <td>0.018663</td>\n",
       "      <td>0.087148</td>\n",
       "      <td>0.007387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052061</td>\n",
       "      <td>0.047621</td>\n",
       "      <td>0.049861</td>\n",
       "      <td>0.048525</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.169205</td>\n",
       "      <td>0.025294</td>\n",
       "      <td>0.004562</td>\n",
       "      <td>0.032405</td>\n",
       "      <td>0.069708</td>\n",
       "      <td>0.007917</td>\n",
       "      <td>0.045086</td>\n",
       "      <td>0.015029</td>\n",
       "      <td>0.097350</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050050</td>\n",
       "      <td>0.054411</td>\n",
       "      <td>0.049782</td>\n",
       "      <td>0.046629</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.011741</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.180053</td>\n",
       "      <td>0.025664</td>\n",
       "      <td>0.008246</td>\n",
       "      <td>0.046101</td>\n",
       "      <td>0.083582</td>\n",
       "      <td>0.005113</td>\n",
       "      <td>0.034121</td>\n",
       "      <td>0.020827</td>\n",
       "      <td>0.088696</td>\n",
       "      <td>0.009058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056879</td>\n",
       "      <td>0.054380</td>\n",
       "      <td>0.050208</td>\n",
       "      <td>0.043260</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.012921</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.223059</td>\n",
       "      <td>0.024581</td>\n",
       "      <td>0.008121</td>\n",
       "      <td>0.013168</td>\n",
       "      <td>0.024215</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>0.096313</td>\n",
       "      <td>0.018802</td>\n",
       "      <td>0.087168</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017668</td>\n",
       "      <td>0.049053</td>\n",
       "      <td>0.054539</td>\n",
       "      <td>0.027507</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.020119</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.219981</td>\n",
       "      <td>0.017919</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>0.013994</td>\n",
       "      <td>0.023060</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.089897</td>\n",
       "      <td>0.016884</td>\n",
       "      <td>0.085151</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023182</td>\n",
       "      <td>0.054121</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>0.032673</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.009096</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.028171</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.229718</td>\n",
       "      <td>0.021067</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.012775</td>\n",
       "      <td>0.029807</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.091439</td>\n",
       "      <td>0.011262</td>\n",
       "      <td>0.070372</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026894</td>\n",
       "      <td>0.047344</td>\n",
       "      <td>0.059615</td>\n",
       "      <td>0.034794</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.019722</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.177559</td>\n",
       "      <td>0.022822</td>\n",
       "      <td>0.019018</td>\n",
       "      <td>0.021784</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.004927</td>\n",
       "      <td>0.066909</td>\n",
       "      <td>0.019018</td>\n",
       "      <td>0.074516</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045902</td>\n",
       "      <td>0.058956</td>\n",
       "      <td>0.054806</td>\n",
       "      <td>0.027835</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.008212</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.023340</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.202369</td>\n",
       "      <td>0.022730</td>\n",
       "      <td>0.019562</td>\n",
       "      <td>0.037057</td>\n",
       "      <td>0.064196</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.033062</td>\n",
       "      <td>0.006750</td>\n",
       "      <td>0.075492</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039399</td>\n",
       "      <td>0.065023</td>\n",
       "      <td>0.046150</td>\n",
       "      <td>0.027828</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.033889</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           a         b         c         d         e         f         g  \\\n",
       "0   0.075952  0.012840  0.045702  0.046137  0.105332  0.015669  0.019151   \n",
       "1   0.084178  0.019912  0.030404  0.038870  0.136998  0.017408  0.031239   \n",
       "2   0.071646  0.012172  0.045643  0.032642  0.120055  0.014661  0.025173   \n",
       "3   0.072210  0.027715  0.029977  0.039593  0.121041  0.016780  0.023567   \n",
       "4   0.073806  0.020368  0.031099  0.039641  0.141261  0.020368  0.020368   \n",
       "5   0.077913  0.014919  0.035749  0.044830  0.149735  0.011784  0.011496   \n",
       "6   0.072717  0.013065  0.035412  0.044990  0.150754  0.010523  0.010582   \n",
       "7   0.072599  0.015761  0.039836  0.051129  0.157111  0.013031  0.013527   \n",
       "8   0.078947  0.011501  0.035283  0.051852  0.143275  0.012086  0.020078   \n",
       "9   0.078738  0.010451  0.037253  0.053283  0.150487  0.016222  0.010708   \n",
       "10  0.126059  0.032387  0.014449  0.034380  0.096662  0.004484  0.059791   \n",
       "11  0.147555  0.024698  0.009199  0.039441  0.093372  0.011089  0.033896   \n",
       "12  0.177360  0.023339  0.005501  0.038741  0.083651  0.012691  0.049585   \n",
       "13  0.169205  0.025294  0.004562  0.032405  0.069708  0.007917  0.045086   \n",
       "14  0.180053  0.025664  0.008246  0.046101  0.083582  0.005113  0.034121   \n",
       "15  0.223059  0.024581  0.008121  0.013168  0.024215  0.003512  0.096313   \n",
       "16  0.219981  0.017919  0.004989  0.013994  0.023060  0.001795  0.089897   \n",
       "17  0.229718  0.021067  0.002521  0.012775  0.029807  0.000280  0.091439   \n",
       "18  0.177559  0.022822  0.019018  0.021784  0.064920  0.004927  0.066909   \n",
       "19  0.202369  0.022730  0.019562  0.037057  0.064196  0.005786  0.033062   \n",
       "\n",
       "           h         i         j  ...         r         s         t         u  \\\n",
       "0   0.043743  0.073993  0.001741  ...  0.077693  0.061371  0.080522  0.025898   \n",
       "1   0.027423  0.075355  0.002623  ...  0.090140  0.071659  0.077739  0.030643   \n",
       "2   0.023513  0.094606  0.002490  ...  0.053942  0.087967  0.081051  0.029046   \n",
       "3   0.059012  0.065234  0.001508  ...  0.059201  0.073341  0.093703  0.024321   \n",
       "4   0.056943  0.065046  0.003285  ...  0.072492  0.059571  0.095488  0.024967   \n",
       "5   0.012613  0.072003  0.002126  ...  0.074741  0.082093  0.070561  0.054452   \n",
       "6   0.011528  0.071416  0.003015  ...  0.076914  0.078333  0.065681  0.050902   \n",
       "7   0.014396  0.085629  0.004344  ...  0.082030  0.066518  0.061057  0.042690   \n",
       "8   0.019493  0.089864  0.003899  ...  0.077778  0.072320  0.063353  0.043860   \n",
       "9   0.015517  0.069377  0.002308  ...  0.075083  0.071621  0.077584  0.053475   \n",
       "10  0.013951  0.104634  0.003986  ...  0.076731  0.069258  0.046836  0.042352   \n",
       "11  0.018523  0.100302  0.005292  ...  0.046623  0.081401  0.050781  0.040575   \n",
       "12  0.018663  0.087148  0.007387  ...  0.052061  0.047621  0.049861  0.048525   \n",
       "13  0.015029  0.097350  0.006642  ...  0.050050  0.054411  0.049782  0.046629   \n",
       "14  0.020827  0.088696  0.009058  ...  0.056879  0.054380  0.050208  0.043260   \n",
       "15  0.018802  0.087168  0.001280  ...  0.017668  0.049053  0.054539  0.027507   \n",
       "16  0.016884  0.085151  0.000700  ...  0.023182  0.054121  0.044872  0.032673   \n",
       "17  0.011262  0.070372  0.001793  ...  0.026894  0.047344  0.059615  0.034794   \n",
       "18  0.019018  0.074516  0.001902  ...  0.045902  0.058956  0.054806  0.027835   \n",
       "19  0.006750  0.075492  0.002342  ...  0.039399  0.065023  0.046150  0.027828   \n",
       "\n",
       "           v         w         x         y         z  Label  \n",
       "0   0.009793  0.014146  0.000653  0.020022  0.000435     en  \n",
       "1   0.013712  0.013950  0.002027  0.010731  0.000596     en  \n",
       "2   0.018811  0.011895  0.000553  0.017981  0.000553     en  \n",
       "3   0.005090  0.019608  0.006033  0.017534  0.001697     en  \n",
       "4   0.010731  0.023872  0.003066  0.014893  0.000657     en  \n",
       "5   0.010631  0.004541  0.003892  0.005334  0.000468     fr  \n",
       "6   0.012711  0.002601  0.004966  0.004848  0.000118     fr  \n",
       "7   0.015140  0.000745  0.005088  0.004964  0.001986     fr  \n",
       "8   0.014035  0.000390  0.003314  0.005263  0.001170     fr  \n",
       "9   0.014299  0.000705  0.003911  0.003655  0.000834     fr  \n",
       "10  0.003986  0.006477  0.001495  0.009467  0.001495     id  \n",
       "11  0.008065  0.005040  0.001386  0.013609  0.000630     id  \n",
       "12  0.001572  0.004086  0.000236  0.014577  0.000236     id  \n",
       "13  0.002214  0.001811  0.000201  0.011741  0.000537     id  \n",
       "14  0.003003  0.006233  0.000308  0.012921  0.001136     id  \n",
       "15  0.002451  0.012400  0.000512  0.020119  0.001061     tl  \n",
       "16  0.000639  0.009096  0.000304  0.028171  0.000152     tl  \n",
       "17  0.001065  0.014287  0.000056  0.019722  0.000056     tl  \n",
       "18  0.005100  0.008212  0.000864  0.023340  0.002680     tl  \n",
       "19  0.004822  0.005786  0.000413  0.033889  0.003031     tl  \n",
       "\n",
       "[20 rows x 27 columns]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang=['en', 'fr', 'id', 'tl']\n",
    "al='abcdefghijklmnopqrstuvwxyz'\n",
    "lang_df={}\n",
    "label=[]\n",
    "new_list=[]\n",
    "\n",
    "for a in al: \n",
    "    lang_df[a]=[]   # df를 위한 딕셔너리\n",
    "\n",
    "for l in lang:\n",
    "    for a in al:\n",
    "        for i in range(1, 6):\n",
    "            with open('./lang/train/'+l+'-'+str(i)+'.txt', encoding='utf-8') as f:\n",
    "                text=f.read().lower()\n",
    "                lang_df[a].append(text.count(a))\n",
    "    \n",
    "    for i in range(5):\n",
    "        label.append(l)\n",
    "\n",
    "\n",
    "    \n",
    "train_df=pd.DataFrame(lang_df)\n",
    "\n",
    "for i in range(20):\n",
    "    new_list.append(train_df.iloc[i]/train_df.sum(axis=1)[i])\n",
    "    \n",
    "train_df=pd.DataFrame(new_list)\n",
    "train_df['Label']=label\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "ed14edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('preprocessing_lang.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca7a08d",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "2e5d968e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>e</th>\n",
       "      <th>f</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>...</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.067823</td>\n",
       "      <td>0.013459</td>\n",
       "      <td>0.034328</td>\n",
       "      <td>0.048817</td>\n",
       "      <td>0.116114</td>\n",
       "      <td>0.020014</td>\n",
       "      <td>0.016002</td>\n",
       "      <td>0.022798</td>\n",
       "      <td>0.076920</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070124</td>\n",
       "      <td>0.079550</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>0.025910</td>\n",
       "      <td>0.014775</td>\n",
       "      <td>0.036103</td>\n",
       "      <td>0.005634</td>\n",
       "      <td>0.013087</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.080283</td>\n",
       "      <td>0.016174</td>\n",
       "      <td>0.035350</td>\n",
       "      <td>0.038342</td>\n",
       "      <td>0.129865</td>\n",
       "      <td>0.016704</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.042697</td>\n",
       "      <td>0.073986</td>\n",
       "      <td>0.004463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066227</td>\n",
       "      <td>0.063599</td>\n",
       "      <td>0.078880</td>\n",
       "      <td>0.027631</td>\n",
       "      <td>0.013026</td>\n",
       "      <td>0.014880</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.056764</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.035835</td>\n",
       "      <td>0.049876</td>\n",
       "      <td>0.127155</td>\n",
       "      <td>0.013476</td>\n",
       "      <td>0.008620</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>0.086050</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067304</td>\n",
       "      <td>0.090078</td>\n",
       "      <td>0.068433</td>\n",
       "      <td>0.042912</td>\n",
       "      <td>0.013852</td>\n",
       "      <td>0.028909</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>0.005157</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.071875</td>\n",
       "      <td>0.011413</td>\n",
       "      <td>0.038476</td>\n",
       "      <td>0.040330</td>\n",
       "      <td>0.139357</td>\n",
       "      <td>0.012185</td>\n",
       "      <td>0.015386</td>\n",
       "      <td>0.018410</td>\n",
       "      <td>0.079491</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064060</td>\n",
       "      <td>0.073023</td>\n",
       "      <td>0.066334</td>\n",
       "      <td>0.048652</td>\n",
       "      <td>0.013598</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.104322</td>\n",
       "      <td>0.022424</td>\n",
       "      <td>0.015275</td>\n",
       "      <td>0.044199</td>\n",
       "      <td>0.089373</td>\n",
       "      <td>0.011375</td>\n",
       "      <td>0.026649</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.090510</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069548</td>\n",
       "      <td>0.079298</td>\n",
       "      <td>0.052811</td>\n",
       "      <td>0.036887</td>\n",
       "      <td>0.016575</td>\n",
       "      <td>0.033637</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.164736</td>\n",
       "      <td>0.026052</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.041574</td>\n",
       "      <td>0.088257</td>\n",
       "      <td>0.006201</td>\n",
       "      <td>0.035997</td>\n",
       "      <td>0.025116</td>\n",
       "      <td>0.082056</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053625</td>\n",
       "      <td>0.048789</td>\n",
       "      <td>0.053235</td>\n",
       "      <td>0.047424</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.014820</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.185554</td>\n",
       "      <td>0.019668</td>\n",
       "      <td>0.014370</td>\n",
       "      <td>0.026720</td>\n",
       "      <td>0.033086</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.082523</td>\n",
       "      <td>0.014065</td>\n",
       "      <td>0.081723</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035830</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>0.052258</td>\n",
       "      <td>0.023899</td>\n",
       "      <td>0.004803</td>\n",
       "      <td>0.028359</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>0.017076</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.167676</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.018765</td>\n",
       "      <td>0.024818</td>\n",
       "      <td>0.055690</td>\n",
       "      <td>0.009080</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>0.011501</td>\n",
       "      <td>0.070218</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044189</td>\n",
       "      <td>0.052663</td>\n",
       "      <td>0.061743</td>\n",
       "      <td>0.037530</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.016344</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.018160</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         b         c         d         e         f         g  \\\n",
       "0  0.067823  0.013459  0.034328  0.048817  0.116114  0.020014  0.016002   \n",
       "1  0.080283  0.016174  0.035350  0.038342  0.129865  0.016704  0.018950   \n",
       "2  0.056764  0.012008  0.035835  0.049876  0.127155  0.013476  0.008620   \n",
       "3  0.071875  0.011413  0.038476  0.040330  0.139357  0.012185  0.015386   \n",
       "4  0.104322  0.022424  0.015275  0.044199  0.089373  0.011375  0.026649   \n",
       "5  0.164736  0.026052  0.014586  0.041574  0.088257  0.006201  0.035997   \n",
       "6  0.185554  0.019668  0.014370  0.026720  0.033086  0.007966  0.082523   \n",
       "7  0.167676  0.016949  0.018765  0.024818  0.055690  0.009080  0.066586   \n",
       "\n",
       "          h         i         j  ...         r         s         t         u  \\\n",
       "0  0.022798  0.076920  0.002411  ...  0.070124  0.079550  0.075122  0.025910   \n",
       "1  0.042697  0.073986  0.004463  ...  0.066227  0.063599  0.078880  0.027631   \n",
       "2  0.007303  0.086050  0.002786  ...  0.067304  0.090078  0.068433  0.042912   \n",
       "3  0.018410  0.079491  0.004150  ...  0.064060  0.073023  0.066334  0.048652   \n",
       "4  0.015600  0.090510  0.005362  ...  0.069548  0.079298  0.052811  0.036887   \n",
       "5  0.025116  0.082056  0.007254  ...  0.053625  0.048789  0.053235  0.047424   \n",
       "6  0.014065  0.081723  0.000229  ...  0.035830  0.058700  0.052258  0.023899   \n",
       "7  0.011501  0.070218  0.000605  ...  0.044189  0.052663  0.061743  0.037530   \n",
       "\n",
       "          v         w         x         y         z  Label  \n",
       "0  0.014775  0.036103  0.005634  0.013087  0.000416     en  \n",
       "1  0.013026  0.014880  0.002119  0.013300  0.001491     en  \n",
       "2  0.013852  0.028909  0.009298  0.005157  0.000414     fr  \n",
       "3  0.013598  0.002892  0.004282  0.003355  0.001192     fr  \n",
       "4  0.016575  0.033637  0.004875  0.009587  0.000487     id  \n",
       "5  0.004680  0.004602  0.000468  0.014820  0.000585     id  \n",
       "6  0.004803  0.028359  0.003392  0.017076  0.000419     tl  \n",
       "7  0.001816  0.016344  0.000605  0.018160  0.000605     tl  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang=['en', 'fr', 'id', 'tl']\n",
    "al='abcdefghijklmnopqrstuvwxyz'\n",
    "lang_df={}\n",
    "label=[]\n",
    "new_list=[]\n",
    "\n",
    "for a in al: \n",
    "    lang_df[a]=[]   # df를 위한 딕셔너리\n",
    "\n",
    "for l in lang:\n",
    "    for a in al:\n",
    "        for i in range(1, 3):\n",
    "            with open('./lang/test/'+l+'-'+str(i)+'.txt', encoding='utf-8') as f:\n",
    "                text=f.read().lower()\n",
    "                lang_df[a].append(text.count(a))\n",
    "    \n",
    "    for i in range(2):\n",
    "        label.append(l)\n",
    "\n",
    "\n",
    "\n",
    "test_df=pd.DataFrame(lang_df)\n",
    "\n",
    "for i in range(8):\n",
    "    new_list.append(test_df.iloc[i]/test_df.sum(axis=1)[i])\n",
    "    \n",
    "test_df=pd.DataFrame(new_list)\n",
    "test_df['Label']=label\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54628c8",
   "metadata": {},
   "source": [
    "### 데이터와 타겟 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e0d34e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_df.iloc[:, :-1]\n",
    "train_target=train_df.iloc[:, -1]\n",
    "\n",
    "test_data=test_df.iloc[:, :-1]\n",
    "test_target=test_df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "5b94e2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 26), (20,), (8, 26), (8,))"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_target.shape, test_data.shape, test_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37032802",
   "metadata": {},
   "source": [
    "### 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "fed887ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "knModel=KNeighborsClassifier(n_neighbors=3)\n",
    "lrModel=LogisticRegression(C=10)\n",
    "sgdModel=SGDClassifier()\n",
    "dtModel=DecisionTreeClassifier(max_depth=4)\n",
    "rfModel=RandomForestClassifier(max_depth=5)\n",
    "svcModel=SVC(degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "805e39fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(degree=2)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knModel.fit(train_data, train_target)\n",
    "lrModel.fit(train_data, train_target)\n",
    "sgdModel.fit(train_data, train_target)\n",
    "dtModel.fit(train_data, train_target)\n",
    "rfModel.fit(train_data, train_target)\n",
    "svcModel.fit(train_data,train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "18448547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knModel train score : 1.0\n",
      "knModel test score : 1.0\n",
      "\n",
      "lrModel train score : 0.85\n",
      "lrModel test score : 0.875\n",
      "\n",
      "sgdModel train score : 0.25\n",
      "sgdModel test score : 0.25\n",
      "\n",
      "dtModel train score : 1.0\n",
      "dtModel test score : 0.625\n",
      "\n",
      "rfModel train score : 1.0\n",
      "rfModel test score : 1.0\n",
      "\n",
      "svcModel train score : 1.0\n",
      "svcModel test score : 1.0\n"
     ]
    }
   ],
   "source": [
    "print('knModel train score :', knModel.score(train_data, train_target))\n",
    "print('knModel test score :', knModel.score(test_data, test_target))\n",
    "print()\n",
    "print('lrModel train score :', lrModel.score(train_data, train_target))\n",
    "print('lrModel test score :', lrModel.score(test_data, test_target))\n",
    "print()\n",
    "print('sgdModel train score :', sgdModel.score(train_data, train_target))\n",
    "print('sgdModel test score :', sgdModel.score(test_data, test_target))\n",
    "print()\n",
    "print('dtModel train score :', dtModel.score(train_data, train_target))\n",
    "print('dtModel test score :', dtModel.score(test_data, test_target))\n",
    "print()\n",
    "print('rfModel train score :', rfModel.score(train_data, train_target))\n",
    "print('rfModel test score :', rfModel.score(test_data, test_target))\n",
    "print()\n",
    "print('svcModel train score :', svcModel.score(train_data, train_target))\n",
    "print('svcModel test score :', svcModel.score(test_data, test_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b138598",
   "metadata": {},
   "source": [
    "### 최적의 모델 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "2690f361",
   "metadata": {},
   "outputs": [],
   "source": [
    "models=all_estimators(type_filter='classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "e9ee71a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "scores=[]\n",
    "\n",
    "for name, model in models:\n",
    "    try:\n",
    "        # 모델 객체 생성\n",
    "        md=model()\n",
    "        # 학습\n",
    "        md.fit(train_data, train_target)\n",
    "        # 평가\n",
    "        result=md.score(test_data, test_target)\n",
    "        scores.append((name, result))\n",
    "        \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a121dca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AdaBoostClassifier', 0.5),\n",
       " ('BaggingClassifier', 0.875),\n",
       " ('BernoulliNB', 0.25),\n",
       " ('CalibratedClassifierCV', 0.875),\n",
       " ('CategoricalNB', 0.25),\n",
       " ('ComplementNB', 0.5),\n",
       " ('DecisionTreeClassifier', 0.875),\n",
       " ('DummyClassifier', 0.25),\n",
       " ('ExtraTreeClassifier', 0.5),\n",
       " ('ExtraTreesClassifier', 1.0),\n",
       " ('GaussianNB', 0.75),\n",
       " ('GaussianProcessClassifier', 0.75),\n",
       " ('GradientBoostingClassifier', 1.0),\n",
       " ('HistGradientBoostingClassifier', 0.25),\n",
       " ('KNeighborsClassifier', 0.75),\n",
       " ('LabelPropagation', 1.0),\n",
       " ('LabelSpreading', 1.0),\n",
       " ('LinearDiscriminantAnalysis', 0.875),\n",
       " ('LinearSVC', 0.75),\n",
       " ('LogisticRegression', 0.75),\n",
       " ('LogisticRegressionCV', 1.0),\n",
       " ('MLPClassifier', 0.875),\n",
       " ('MultinomialNB', 0.625),\n",
       " ('NearestCentroid', 1.0),\n",
       " ('NuSVC', 1.0),\n",
       " ('PassiveAggressiveClassifier', 0.5),\n",
       " ('Perceptron', 0.5),\n",
       " ('QuadraticDiscriminantAnalysis', 0.25),\n",
       " ('RadiusNeighborsClassifier', 0.25),\n",
       " ('RandomForestClassifier', 1.0),\n",
       " ('RidgeClassifier', 0.75),\n",
       " ('RidgeClassifierCV', 0.875),\n",
       " ('SGDClassifier', 0.5),\n",
       " ('SVC', 1.0)]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e50a06",
   "metadata": {},
   "source": [
    "### 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "2c5e4ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#sentence=\"This is the true joy in life, the being used for a purpose recognized by yourself as a mighty one instead of a feverish selfish little clod of ailments and grievances complaining that the world will not devote itself to making you happy.\"\n",
    "sentence=\"Vous souvenez-vous de l’expression que nous avons vue la dernière fois ?\"\n",
    "stc_dict={}\n",
    "\n",
    "for a in al:\n",
    "    stc_dict[a]=sentence.count(a)\n",
    "    \n",
    "pred=pd.Series(stc_dict)/(pd.Series(stc_dict).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "f6df39f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knModel => ['fr']\n",
      "lrModel => ['fr']\n",
      "sgdModel => ['en']\n",
      "dtModel => ['fr']\n",
      "rfModel => ['fr']\n",
      "svcModel => ['fr']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print('knModel =>', knModel.predict([pred]))\n",
    "print('lrModel =>', lrModel.predict([pred]))\n",
    "print('sgdModel =>', sgdModel.predict([pred]))\n",
    "print('dtModel =>', dtModel.predict([pred]))\n",
    "print('rfModel =>', rfModel.predict([pred]))\n",
    "print('svcModel =>', svcModel.predict([pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afac997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
