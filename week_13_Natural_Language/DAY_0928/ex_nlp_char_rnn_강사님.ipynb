{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e373fa7",
   "metadata": {},
   "source": [
    "### 문자 단위 RNN 언어 모델(Char RNNLM)\n",
    "---\n",
    "- 입출력 단위 ==> 단어 레벨(word-level)에서 문자 레벨(character-level)로 변경\n",
    "- 이전 시점의 예측 문자 => 다음 시점의 입력으로 사용\n",
    "- 구조 : 다 대 다(Many-to-Many) 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e15173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib.request\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11416ed3",
   "metadata": {},
   "source": [
    "### [1] 데이터 준비\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb2dd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('11-0.txt', <http.client.HTTPMessage at 0x1f5af354c10>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", \n",
    "                           filename=\"11-0.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e05741d",
   "metadata": {},
   "source": [
    "### [2] 데이터 전처리\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24bfa6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수문자 제거, 단어 소문자화 수행\n",
    "f = open('11-0.txt', 'rb')\n",
    "sentences = []\n",
    "for sentence in f: \n",
    "    sentence = sentence.strip() # \\r, \\n 개행 공백 문자 제거\n",
    "    sentence = sentence.lower() # 소문자화.\n",
    "    sentence = sentence.decode('ascii', 'ignore') # \\xe2\\x80\\x99 등과 같은 바이트 열 제거\n",
    "    if len(sentence) > 0: sentences.append(sentence)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11cf9255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the project gutenberg ebook of alices adventures in wonderland, by lewis carroll',\n",
       " 'this ebook is for the use of anyone anywhere in the united states and',\n",
       " 'most other parts of the world at no cost and with almost no restrictions',\n",
       " 'whatsoever. you may copy it, give it away or re-use it under the terms',\n",
       " 'of the project gutenberg license included with this ebook or online at']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf88ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자열의 길이 또는 총 문자의 개수: 159484\n"
     ]
    }
   ],
   "source": [
    "# 하나의 문자열로 통합 ----------------------------------\n",
    "total_data = ' '.join(sentences)\n",
    "print('문자열의 길이 또는 총 문자의 개수: %d' % len(total_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79693733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the project gutenberg ebook of alices adventures in wonderland, by lewis carroll this ebook is for the use of anyone anywhere in the united states and most other parts of the world at no cost and with\n"
     ]
    }
   ],
   "source": [
    "print(total_data[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70b90bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열로부터 문자 집합 생성 => 중복 문자 제거\n",
    "char_vocab = sorted(list(set(total_data)))\n",
    "vocab_size = len(char_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37681049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자 집합의 크기 : 56\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "print ('문자 집합의 크기 : {}'.format(vocab_size))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca0e178d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자 집합 : {' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, '[': 27, ']': 28, '_': 29, 'a': 30, 'b': 31, 'c': 32, 'd': 33, 'e': 34, 'f': 35, 'g': 36, 'h': 37, 'i': 38, 'j': 39, 'k': 40, 'l': 41, 'm': 42, 'n': 43, 'o': 44, 'p': 45, 'q': 46, 'r': 47, 's': 48, 't': 49, 'u': 50, 'v': 51, 'w': 52, 'x': 53, 'y': 54, 'z': 55}\n"
     ]
    }
   ],
   "source": [
    "# 문자에 고유한 정수 부여\n",
    "# 정수 0 ~ 28 : 공백 포함한 각종 구두점, 특수문자\n",
    "# 정수 29~ 54 : a부터 z까지 총 26개의 알파벳 소문자\n",
    "char_to_index = dict((char, index) for index, char in enumerate(char_vocab))\n",
    "print('문자 집합 :',char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27c4104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인덱스에 해당하는 문자 변환을 위한 dict 생성\n",
    "index_to_char = {}\n",
    "for key, value in char_to_index.items():\n",
    "    index_to_char[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0035c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appl (입력 시퀀스) -> pple (예측해야하는 시퀀스)\n",
    "train_X = 'appl'\n",
    "train_y = 'pple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47c60df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 수 : 2658\n"
     ]
    }
   ],
   "source": [
    "# 샘플 데이터 생성\n",
    "# - 문장 샘플의 길이 결정\n",
    "# - 해당 길이만큼 문자열 전체 등분\n",
    "seq_length = 60\n",
    "\n",
    "# 문자열의 길이를 seq_length로 나누면 전처리 후 생겨날 샘플 수\n",
    "n_samples = int(np.floor((len(total_data) - 1) / seq_length))\n",
    "print ('샘플의 수 : {}'.format(n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04a00f4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (890424493.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [15]\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(f'X_encoded : {X_encoded}')\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "train_X = []\n",
    "train_y = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    # 0:60 -> 60:120 -> 120:180\n",
    "    X_sample = total_data[i * seq_length: (i + 1) * seq_length]\n",
    "    print(f'X_sample : {X_sample}')\n",
    "\n",
    "    # 정수 인코딩\n",
    "    X_encoded = [char_to_index[c] for c in X_sample]\n",
    "    train_X.append(X_encoded)\n",
    "    print(f'X_encoded : {X_encoded}')\n",
    "\n",
    "    # 오른쪽으로 1칸 쉬프트\n",
    "    y_sample = total_data[i * seq_length + 1: (i + 1) * seq_length + 1]\n",
    "    y_encoded = [char_to_index[c] for c in y_sample]\n",
    "    train_y.append(y_encoded)\n",
    "     print(f'X_encoded : {X_encoded}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8b91158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 데이터의 첫번째 샘플 : [49, 37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30]\n",
      "y 데이터의 첫번째 샘플 : [37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30, 43]\n",
      "--------------------------------------------------\n",
      "X 데이터의 첫번째 샘플 디코딩 : ['t', 'h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', 'o', 'f', ' ', 'a', 'l', 'i', 'c', 'e', 's', ' ', 'a', 'd', 'v', 'e', 'n', 't', 'u', 'r', 'e', 's', ' ', 'i', 'n', ' ', 'w', 'o', 'n', 'd', 'e', 'r', 'l', 'a']\n",
      "y 데이터의 첫번째 샘플 디코딩 : ['h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', 'o', 'f', ' ', 'a', 'l', 'i', 'c', 'e', 's', ' ', 'a', 'd', 'v', 'e', 'n', 't', 'u', 'r', 'e', 's', ' ', 'i', 'n', ' ', 'w', 'o', 'n', 'd', 'e', 'r', 'l', 'a', 'n']\n"
     ]
    }
   ],
   "source": [
    "print('X 데이터의 첫번째 샘플 :',train_X[0])\n",
    "print('y 데이터의 첫번째 샘플 :',train_y[0])\n",
    "print('-'*50)\n",
    "print('X 데이터의 첫번째 샘플 디코딩 :',[index_to_char[i] for i in train_X[0]])\n",
    "print('y 데이터의 첫번째 샘플 디코딩 :',[index_to_char[i] for i in train_y[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8919f008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43, 33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54]\n",
      "[33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54, 52]\n"
     ]
    }
   ],
   "source": [
    "print(train_X[1], train_y[1], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4e27046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X의 크기(shape) : (2658, 60, 56)\n",
      "train_y의 크기(shape) : (2658, 60, 56)\n"
     ]
    }
   ],
   "source": [
    "train_X = to_categorical(train_X)\n",
    "train_y = to_categorical(train_y)\n",
    "\n",
    "print('train_X의 크기(shape) : {}'.format(train_X.shape)) # 원-핫 인코딩\n",
    "print('train_y의 크기(shape) : {}'.format(train_y.shape)) # 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5136c1d",
   "metadata": {},
   "source": [
    "## Model\n",
    "---\n",
    "- 문자 단위 RNN에서는 입력 시퀀스에 대해서 워드 임베딩 하지 않음\n",
    "- 입력 시퀀스인 train_X에 대해서도 원-핫 인코딩 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2037aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4427fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5c2af78",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "84/84 - 40s - loss: 3.0658 - accuracy: 0.1829 - 40s/epoch - 482ms/step\n",
      "Epoch 2/80\n",
      "84/84 - 45s - loss: 2.8132 - accuracy: 0.2274 - 45s/epoch - 536ms/step\n",
      "Epoch 3/80\n",
      "84/84 - 74s - loss: 2.4659 - accuracy: 0.3153 - 74s/epoch - 878ms/step\n",
      "Epoch 4/80\n",
      "84/84 - 50s - loss: 2.3309 - accuracy: 0.3408 - 50s/epoch - 601ms/step\n",
      "Epoch 5/80\n",
      "84/84 - 37s - loss: 2.2404 - accuracy: 0.3619 - 37s/epoch - 443ms/step\n",
      "Epoch 6/80\n",
      "84/84 - 50s - loss: 2.1677 - accuracy: 0.3823 - 50s/epoch - 598ms/step\n",
      "Epoch 7/80\n",
      "84/84 - 43s - loss: 2.1041 - accuracy: 0.3978 - 43s/epoch - 509ms/step\n",
      "Epoch 8/80\n",
      "84/84 - 34s - loss: 2.0474 - accuracy: 0.4119 - 34s/epoch - 401ms/step\n",
      "Epoch 9/80\n",
      "84/84 - 38s - loss: 2.0008 - accuracy: 0.4242 - 38s/epoch - 453ms/step\n",
      "Epoch 10/80\n",
      "84/84 - 56s - loss: 1.9617 - accuracy: 0.4337 - 56s/epoch - 667ms/step\n",
      "Epoch 11/80\n",
      "84/84 - 40s - loss: 1.9242 - accuracy: 0.4423 - 40s/epoch - 481ms/step\n",
      "Epoch 12/80\n",
      "84/84 - 35s - loss: 1.8935 - accuracy: 0.4516 - 35s/epoch - 411ms/step\n",
      "Epoch 13/80\n",
      "84/84 - 41s - loss: 1.8570 - accuracy: 0.4616 - 41s/epoch - 483ms/step\n",
      "Epoch 14/80\n",
      "84/84 - 55s - loss: 1.8274 - accuracy: 0.4685 - 55s/epoch - 652ms/step\n",
      "Epoch 15/80\n",
      "84/84 - 34s - loss: 1.8017 - accuracy: 0.4759 - 34s/epoch - 400ms/step\n",
      "Epoch 16/80\n",
      "84/84 - 33s - loss: 1.7743 - accuracy: 0.4831 - 33s/epoch - 394ms/step\n",
      "Epoch 17/80\n",
      "84/84 - 41s - loss: 1.7527 - accuracy: 0.4890 - 41s/epoch - 484ms/step\n",
      "Epoch 18/80\n",
      "84/84 - 53s - loss: 1.7294 - accuracy: 0.4951 - 53s/epoch - 626ms/step\n",
      "Epoch 19/80\n",
      "84/84 - 37s - loss: 1.7071 - accuracy: 0.5017 - 37s/epoch - 442ms/step\n",
      "Epoch 20/80\n",
      "84/84 - 36s - loss: 1.6863 - accuracy: 0.5061 - 36s/epoch - 432ms/step\n",
      "Epoch 21/80\n",
      "84/84 - 46s - loss: 1.6629 - accuracy: 0.5132 - 46s/epoch - 542ms/step\n",
      "Epoch 22/80\n",
      "84/84 - 40s - loss: 1.6435 - accuracy: 0.5175 - 40s/epoch - 478ms/step\n",
      "Epoch 23/80\n",
      "84/84 - 31s - loss: 1.6248 - accuracy: 0.5229 - 31s/epoch - 372ms/step\n",
      "Epoch 24/80\n",
      "84/84 - 30s - loss: 1.6029 - accuracy: 0.5292 - 30s/epoch - 354ms/step\n",
      "Epoch 25/80\n",
      "84/84 - 35s - loss: 1.5837 - accuracy: 0.5332 - 35s/epoch - 416ms/step\n",
      "Epoch 26/80\n",
      "84/84 - 47s - loss: 1.5654 - accuracy: 0.5385 - 47s/epoch - 557ms/step\n",
      "Epoch 27/80\n",
      "84/84 - 34s - loss: 1.5481 - accuracy: 0.5425 - 34s/epoch - 401ms/step\n",
      "Epoch 28/80\n",
      "84/84 - 30s - loss: 1.5271 - accuracy: 0.5479 - 30s/epoch - 358ms/step\n",
      "Epoch 29/80\n",
      "84/84 - 34s - loss: 1.5100 - accuracy: 0.5526 - 34s/epoch - 401ms/step\n",
      "Epoch 30/80\n",
      "84/84 - 45s - loss: 1.4893 - accuracy: 0.5581 - 45s/epoch - 541ms/step\n",
      "Epoch 31/80\n",
      "84/84 - 38s - loss: 1.4751 - accuracy: 0.5617 - 38s/epoch - 451ms/step\n",
      "Epoch 32/80\n",
      "84/84 - 35s - loss: 1.4575 - accuracy: 0.5659 - 35s/epoch - 413ms/step\n",
      "Epoch 33/80\n",
      "84/84 - 39s - loss: 1.4376 - accuracy: 0.5714 - 39s/epoch - 469ms/step\n",
      "Epoch 34/80\n",
      "84/84 - 54s - loss: 1.4192 - accuracy: 0.5766 - 54s/epoch - 642ms/step\n",
      "Epoch 35/80\n",
      "84/84 - 37s - loss: 1.4014 - accuracy: 0.5815 - 37s/epoch - 446ms/step\n",
      "Epoch 36/80\n",
      "84/84 - 34s - loss: 1.3877 - accuracy: 0.5860 - 34s/epoch - 407ms/step\n",
      "Epoch 37/80\n",
      "84/84 - 62s - loss: 1.3689 - accuracy: 0.5914 - 62s/epoch - 732ms/step\n",
      "Epoch 38/80\n",
      "84/84 - 46s - loss: 1.3506 - accuracy: 0.5963 - 46s/epoch - 544ms/step\n",
      "Epoch 39/80\n",
      "84/84 - 36s - loss: 1.3362 - accuracy: 0.5998 - 36s/epoch - 427ms/step\n",
      "Epoch 40/80\n",
      "84/84 - 52s - loss: 1.3163 - accuracy: 0.6063 - 52s/epoch - 615ms/step\n",
      "Epoch 41/80\n",
      "84/84 - 55s - loss: 1.3014 - accuracy: 0.6109 - 55s/epoch - 658ms/step\n",
      "Epoch 42/80\n",
      "84/84 - 33s - loss: 1.2881 - accuracy: 0.6144 - 33s/epoch - 389ms/step\n",
      "Epoch 43/80\n",
      "84/84 - 39s - loss: 1.2697 - accuracy: 0.6190 - 39s/epoch - 465ms/step\n",
      "Epoch 44/80\n",
      "84/84 - 55s - loss: 1.2505 - accuracy: 0.6260 - 55s/epoch - 658ms/step\n",
      "Epoch 45/80\n",
      "84/84 - 37s - loss: 1.2372 - accuracy: 0.6285 - 37s/epoch - 444ms/step\n",
      "Epoch 46/80\n",
      "84/84 - 34s - loss: 1.2201 - accuracy: 0.6329 - 34s/epoch - 410ms/step\n",
      "Epoch 47/80\n",
      "84/84 - 45s - loss: 1.2022 - accuracy: 0.6390 - 45s/epoch - 533ms/step\n",
      "Epoch 48/80\n",
      "84/84 - 55s - loss: 1.1823 - accuracy: 0.6447 - 55s/epoch - 657ms/step\n",
      "Epoch 49/80\n",
      "84/84 - 35s - loss: 1.1671 - accuracy: 0.6484 - 35s/epoch - 413ms/step\n",
      "Epoch 50/80\n",
      "84/84 - 39s - loss: 1.1504 - accuracy: 0.6545 - 39s/epoch - 462ms/step\n",
      "Epoch 51/80\n",
      "84/84 - 55s - loss: 1.1347 - accuracy: 0.6581 - 55s/epoch - 653ms/step\n",
      "Epoch 52/80\n",
      "84/84 - 41s - loss: 1.1176 - accuracy: 0.6639 - 41s/epoch - 484ms/step\n",
      "Epoch 53/80\n",
      "84/84 - 32s - loss: 1.1000 - accuracy: 0.6693 - 32s/epoch - 385ms/step\n",
      "Epoch 54/80\n",
      "84/84 - 41s - loss: 1.0808 - accuracy: 0.6749 - 41s/epoch - 490ms/step\n",
      "Epoch 55/80\n",
      "84/84 - 49s - loss: 1.0642 - accuracy: 0.6800 - 49s/epoch - 578ms/step\n",
      "Epoch 56/80\n",
      "84/84 - 34s - loss: 1.0480 - accuracy: 0.6840 - 34s/epoch - 401ms/step\n",
      "Epoch 57/80\n",
      "84/84 - 31s - loss: 1.0290 - accuracy: 0.6902 - 31s/epoch - 368ms/step\n",
      "Epoch 58/80\n",
      "84/84 - 40s - loss: 1.0104 - accuracy: 0.6964 - 40s/epoch - 477ms/step\n",
      "Epoch 59/80\n",
      "84/84 - 54s - loss: 0.9956 - accuracy: 0.7001 - 54s/epoch - 640ms/step\n",
      "Epoch 60/80\n",
      "84/84 - 39s - loss: 0.9703 - accuracy: 0.7090 - 39s/epoch - 465ms/step\n",
      "Epoch 61/80\n",
      "84/84 - 38s - loss: 0.9553 - accuracy: 0.7133 - 38s/epoch - 450ms/step\n",
      "Epoch 62/80\n",
      "84/84 - 51s - loss: 0.9381 - accuracy: 0.7178 - 51s/epoch - 602ms/step\n",
      "Epoch 63/80\n",
      "84/84 - 43s - loss: 0.9158 - accuracy: 0.7255 - 43s/epoch - 513ms/step\n",
      "Epoch 64/80\n",
      "84/84 - 34s - loss: 0.8993 - accuracy: 0.7310 - 34s/epoch - 409ms/step\n",
      "Epoch 65/80\n",
      "84/84 - 42s - loss: 0.8790 - accuracy: 0.7378 - 42s/epoch - 499ms/step\n",
      "Epoch 66/80\n",
      "84/84 - 49s - loss: 0.8596 - accuracy: 0.7433 - 49s/epoch - 584ms/step\n",
      "Epoch 67/80\n",
      "84/84 - 37s - loss: 0.8445 - accuracy: 0.7485 - 37s/epoch - 438ms/step\n",
      "Epoch 68/80\n",
      "84/84 - 36s - loss: 0.8235 - accuracy: 0.7544 - 36s/epoch - 423ms/step\n",
      "Epoch 69/80\n",
      "84/84 - 45s - loss: 0.8034 - accuracy: 0.7612 - 45s/epoch - 531ms/step\n",
      "Epoch 70/80\n",
      "84/84 - 57s - loss: 0.7879 - accuracy: 0.7654 - 57s/epoch - 680ms/step\n",
      "Epoch 71/80\n",
      "84/84 - 39s - loss: 0.7729 - accuracy: 0.7699 - 39s/epoch - 469ms/step\n",
      "Epoch 72/80\n",
      "84/84 - 38s - loss: 0.7474 - accuracy: 0.7790 - 38s/epoch - 456ms/step\n",
      "Epoch 73/80\n",
      "84/84 - 60s - loss: 0.7375 - accuracy: 0.7816 - 60s/epoch - 717ms/step\n",
      "Epoch 74/80\n",
      "84/84 - 46s - loss: 0.7138 - accuracy: 0.7898 - 46s/epoch - 545ms/step\n",
      "Epoch 75/80\n",
      "84/84 - 36s - loss: 0.6951 - accuracy: 0.7956 - 36s/epoch - 424ms/step\n",
      "Epoch 76/80\n",
      "84/84 - 45s - loss: 0.6783 - accuracy: 0.8006 - 45s/epoch - 530ms/step\n",
      "Epoch 77/80\n",
      "84/84 - 60s - loss: 0.6674 - accuracy: 0.8042 - 60s/epoch - 711ms/step\n",
      "Epoch 78/80\n",
      "84/84 - 49s - loss: 0.6523 - accuracy: 0.8086 - 49s/epoch - 580ms/step\n",
      "Epoch 79/80\n",
      "84/84 - 54s - loss: 0.6255 - accuracy: 0.8180 - 54s/epoch - 648ms/step\n",
      "Epoch 80/80\n",
      "84/84 - 57s - loss: 0.6100 - accuracy: 0.8238 - 57s/epoch - 675ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21d21263d00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(hidden_units, \n",
    "               input_shape=(None, train_X.shape[2]), \n",
    "               return_sequences=True))\n",
    "model.add(LSTM(hidden_units, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb57c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d07cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7008007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_X, train_y, epochs=80, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538644ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, length):\n",
    "    # 문자에 대한 랜덤한 정수 생성\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "\n",
    "    # 랜덤한 정수로부터 맵핑되는 문자 생성\n",
    "    y_char = [index_to_char[ix[-1]]]\n",
    "    print(ix[-1],'번 문자',y_char[-1],'로 예측을 시작!')\n",
    "\n",
    "    # (1, length, 55) 크기의 X 생성. 즉, LSTM의 입력 시퀀스 생성\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "\n",
    "    for i in range(length):\n",
    "        # X[0][i][예측한 문자의 인덱스] = 1, 즉, 예측 문자를 다음 입력 시퀀스에 추가\n",
    "        X[0][i][ix[-1]] = 1\n",
    "        print(index_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(index_to_char[ix[-1]])\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32730e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sentence_generation(model, 100)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999ccc2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e58919b7",
   "metadata": {},
   "source": [
    "### 문자 단위 RNN(Char RNN)으로 텍스트 생성\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad1a8565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df670462",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = '''\n",
    "I get on with life as a programmer,\n",
    "I like to contemplate beer.\n",
    "But when I start to daydream,\n",
    "My mind turns straight to wine.\n",
    "\n",
    "Do I love wine more than beer?\n",
    "\n",
    "I like to use words about beer.\n",
    "But when I stop my talking,\n",
    "My mind turns straight to wine.\n",
    "\n",
    "I hate bugs and errors.\n",
    "But I just think back to wine,\n",
    "And I'm happy once again.\n",
    "\n",
    "I like to hang out with programming and deep learning.\n",
    "But when left alone,\n",
    "My mind turns straight to wine.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "406f16a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I get on with life as a programmer, I like to contemplate beer. But when I start to daydream, My mind turns straight to wine. Do I love wine more than beer? I like to use words about beer. But when I stop my talking, My mind turns straight to wine. I hate bugs and errors. But I just think back to wine, And I'm happy once again. I like to hang out with programming and deep learning. But when left alone, My mind turns straight to wine.\n"
     ]
    }
   ],
   "source": [
    "tokens = raw_text.split()\n",
    "raw_text = ' '.join(tokens)\n",
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08bae60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자 집합 : [' ', \"'\", ',', '.', '?', 'A', 'B', 'D', 'I', 'M', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n",
      "문자 집합의 크기 : 33\n"
     ]
    }
   ],
   "source": [
    "# 중복을 제거한 문자 집합 생성\n",
    "char_vocab = sorted(list(set(raw_text)))\n",
    "vocab_size = len(char_vocab)\n",
    "print('문자 집합 :',char_vocab)\n",
    "print ('문자 집합의 크기 : {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c8f4186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, \"'\": 1, ',': 2, '.': 3, '?': 4, 'A': 5, 'B': 6, 'D': 7, 'I': 8, 'M': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14, 'f': 15, 'g': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'l': 21, 'm': 22, 'n': 23, 'o': 24, 'p': 25, 'r': 26, 's': 27, 't': 28, 'u': 29, 'v': 30, 'w': 31, 'y': 32}\n"
     ]
    }
   ],
   "source": [
    "# 문자에 고유한 정수 인덱스 부여\n",
    "char_to_index = dict((char, index) for index, char in enumerate(char_vocab)) \n",
    "\n",
    "\n",
    "print(char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18d73365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 훈련 샘플의 수: 426\n"
     ]
    }
   ],
   "source": [
    "length = 11\n",
    "sequences = []\n",
    "for i in range(length, len(raw_text)):\n",
    "    seq = raw_text[i-length:i] # 길이 11의 문자열을 지속적으로 만든다.\n",
    "    sequences.append(seq)\n",
    "print('총 훈련 샘플의 수: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8670141e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I get on wi',\n",
       " ' get on wit',\n",
       " 'get on with',\n",
       " 'et on with ',\n",
       " 't on with l',\n",
       " ' on with li',\n",
       " 'on with lif',\n",
       " 'n with life',\n",
       " ' with life ',\n",
       " 'with life a']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f00a6039",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences = []\n",
    "for sequence in sequences: # 전체 데이터에서 문장 샘플을 1개씩 꺼낸다.\n",
    "    encoded_sequence = [char_to_index[char] for char in sequence] # 문장 샘플에서 각 문자에 대해서 정수 인코딩을 수행.\n",
    "    encoded_sequences.append(encoded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d61917a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8, 0, 16, 14, 28, 0, 24, 23, 0, 31, 18],\n",
       " [0, 16, 14, 28, 0, 24, 23, 0, 31, 18, 28],\n",
       " [16, 14, 28, 0, 24, 23, 0, 31, 18, 28, 17],\n",
       " [14, 28, 0, 24, 23, 0, 31, 18, 28, 17, 0],\n",
       " [28, 0, 24, 23, 0, 31, 18, 28, 17, 0, 21]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad08e02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences = np.array(encoded_sequences)\n",
    "\n",
    "# 맨 마지막 위치의 문자를 분리\n",
    "X_data = encoded_sequences[:,:-1]\n",
    "# 맨 마지막 위치의 문자를 저장\n",
    "y_data = encoded_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1375eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  0 16 14 28  0 24 23  0 31]\n",
      " [ 0 16 14 28  0 24 23  0 31 18]\n",
      " [16 14 28  0 24 23  0 31 18 28]\n",
      " [14 28  0 24 23  0 31 18 28 17]\n",
      " [28  0 24 23  0 31 18 28 17  0]]\n",
      "[18 28 17  0 21]\n"
     ]
    }
   ],
   "source": [
    "print(X_data[:5])\n",
    "print(y_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5508131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원-핫 인코딩\n",
    "X_data_one_hot = [to_categorical(encoded, num_classes=vocab_size) for encoded in X_data]\n",
    "X_data_one_hot = np.array(X_data_one_hot)\n",
    "y_data_one_hot = to_categorical(y_data, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee04867b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 10, 33)\n"
     ]
    }
   ],
   "source": [
    "print(X_data_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6670e3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 64)                25088     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 33)                2145      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,233\n",
      "Trainable params: 27,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "hidden_units = 64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(hidden_units, \n",
    "               input_shape=(X_data_one_hot.shape[1], X_data_one_hot.shape[2])))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6278c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65f3d9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90313b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 3s - loss: 3.4730 - accuracy: 0.0751 - 3s/epoch - 220ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 3.3646 - accuracy: 0.1972 - 79ms/epoch - 6ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 3.1276 - accuracy: 0.1972 - 60ms/epoch - 4ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 2.9922 - accuracy: 0.1972 - 60ms/epoch - 4ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 2.9619 - accuracy: 0.1972 - 57ms/epoch - 4ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 2.9445 - accuracy: 0.1972 - 66ms/epoch - 5ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 2.9306 - accuracy: 0.1972 - 60ms/epoch - 4ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 2.9112 - accuracy: 0.1972 - 58ms/epoch - 4ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 2.8976 - accuracy: 0.1972 - 65ms/epoch - 5ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 2.8822 - accuracy: 0.1972 - 57ms/epoch - 4ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 2.8590 - accuracy: 0.1972 - 58ms/epoch - 4ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 2.8271 - accuracy: 0.1972 - 67ms/epoch - 5ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 2.8036 - accuracy: 0.1972 - 64ms/epoch - 5ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 2.7666 - accuracy: 0.2019 - 67ms/epoch - 5ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 2.7200 - accuracy: 0.2042 - 71ms/epoch - 5ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 2.6806 - accuracy: 0.2371 - 68ms/epoch - 5ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 2.6348 - accuracy: 0.2441 - 80ms/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 2.6019 - accuracy: 0.2418 - 96ms/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 2.5573 - accuracy: 0.2488 - 79ms/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 2.5273 - accuracy: 0.2840 - 105ms/epoch - 7ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 2.4621 - accuracy: 0.2887 - 122ms/epoch - 9ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 2.4150 - accuracy: 0.2911 - 89ms/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 2.3606 - accuracy: 0.3052 - 85ms/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 2.3135 - accuracy: 0.3427 - 90ms/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 2.2801 - accuracy: 0.3310 - 105ms/epoch - 8ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 2.2343 - accuracy: 0.3592 - 92ms/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 2.1881 - accuracy: 0.3709 - 73ms/epoch - 5ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 2.1487 - accuracy: 0.3967 - 74ms/epoch - 5ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 2.1144 - accuracy: 0.3756 - 79ms/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 2.0619 - accuracy: 0.3850 - 89ms/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 2.0229 - accuracy: 0.4061 - 86ms/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.9777 - accuracy: 0.4366 - 70ms/epoch - 5ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.9362 - accuracy: 0.4437 - 66ms/epoch - 5ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.8707 - accuracy: 0.4554 - 62ms/epoch - 4ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.8303 - accuracy: 0.4836 - 62ms/epoch - 4ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.8029 - accuracy: 0.5329 - 75ms/epoch - 5ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.7587 - accuracy: 0.4836 - 90ms/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.7278 - accuracy: 0.5305 - 92ms/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6817 - accuracy: 0.5493 - 89ms/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6731 - accuracy: 0.5399 - 64ms/epoch - 5ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.6179 - accuracy: 0.5822 - 73ms/epoch - 5ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.5737 - accuracy: 0.5704 - 58ms/epoch - 4ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.5302 - accuracy: 0.6080 - 67ms/epoch - 5ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.4955 - accuracy: 0.6150 - 63ms/epoch - 4ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.4543 - accuracy: 0.6338 - 66ms/epoch - 5ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.4272 - accuracy: 0.6385 - 68ms/epoch - 5ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.4028 - accuracy: 0.6502 - 65ms/epoch - 5ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.3583 - accuracy: 0.6761 - 68ms/epoch - 5ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.3295 - accuracy: 0.6643 - 62ms/epoch - 4ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.3101 - accuracy: 0.6667 - 60ms/epoch - 4ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.2699 - accuracy: 0.6878 - 71ms/epoch - 5ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.2501 - accuracy: 0.6901 - 86ms/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.2036 - accuracy: 0.6901 - 91ms/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.1731 - accuracy: 0.6995 - 93ms/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.1690 - accuracy: 0.7113 - 90ms/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.1487 - accuracy: 0.7394 - 67ms/epoch - 5ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.0979 - accuracy: 0.7488 - 67ms/epoch - 5ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.0655 - accuracy: 0.7488 - 77ms/epoch - 5ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 1.0392 - accuracy: 0.7488 - 75ms/epoch - 5ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 1.0131 - accuracy: 0.7559 - 79ms/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 0.9831 - accuracy: 0.7770 - 77ms/epoch - 5ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 0.9585 - accuracy: 0.7817 - 66ms/epoch - 5ms/step\n",
      "Epoch 63/100\n",
      "14/14 - 0s - loss: 0.9179 - accuracy: 0.7958 - 64ms/epoch - 5ms/step\n",
      "Epoch 64/100\n",
      "14/14 - 0s - loss: 0.8848 - accuracy: 0.8028 - 64ms/epoch - 5ms/step\n",
      "Epoch 65/100\n",
      "14/14 - 0s - loss: 0.8587 - accuracy: 0.8122 - 76ms/epoch - 5ms/step\n",
      "Epoch 66/100\n",
      "14/14 - 0s - loss: 0.8394 - accuracy: 0.8239 - 103ms/epoch - 7ms/step\n",
      "Epoch 67/100\n",
      "14/14 - 0s - loss: 0.8222 - accuracy: 0.8216 - 92ms/epoch - 7ms/step\n",
      "Epoch 68/100\n",
      "14/14 - 0s - loss: 0.7937 - accuracy: 0.8310 - 84ms/epoch - 6ms/step\n",
      "Epoch 69/100\n",
      "14/14 - 0s - loss: 0.7692 - accuracy: 0.8474 - 76ms/epoch - 5ms/step\n",
      "Epoch 70/100\n",
      "14/14 - 0s - loss: 0.7452 - accuracy: 0.8498 - 75ms/epoch - 5ms/step\n",
      "Epoch 71/100\n",
      "14/14 - 0s - loss: 0.7321 - accuracy: 0.8427 - 60ms/epoch - 4ms/step\n",
      "Epoch 72/100\n",
      "14/14 - 0s - loss: 0.7164 - accuracy: 0.8474 - 76ms/epoch - 5ms/step\n",
      "Epoch 73/100\n",
      "14/14 - 0s - loss: 0.6854 - accuracy: 0.8732 - 79ms/epoch - 6ms/step\n",
      "Epoch 74/100\n",
      "14/14 - 0s - loss: 0.6606 - accuracy: 0.8709 - 110ms/epoch - 8ms/step\n",
      "Epoch 75/100\n",
      "14/14 - 0s - loss: 0.6396 - accuracy: 0.8756 - 76ms/epoch - 5ms/step\n",
      "Epoch 76/100\n",
      "14/14 - 0s - loss: 0.6265 - accuracy: 0.8826 - 62ms/epoch - 4ms/step\n",
      "Epoch 77/100\n",
      "14/14 - 0s - loss: 0.6039 - accuracy: 0.8967 - 68ms/epoch - 5ms/step\n",
      "Epoch 78/100\n",
      "14/14 - 0s - loss: 0.5890 - accuracy: 0.8967 - 87ms/epoch - 6ms/step\n",
      "Epoch 79/100\n",
      "14/14 - 0s - loss: 0.5552 - accuracy: 0.9249 - 87ms/epoch - 6ms/step\n",
      "Epoch 80/100\n",
      "14/14 - 0s - loss: 0.5515 - accuracy: 0.9155 - 81ms/epoch - 6ms/step\n",
      "Epoch 81/100\n",
      "14/14 - 0s - loss: 0.5320 - accuracy: 0.9225 - 74ms/epoch - 5ms/step\n",
      "Epoch 82/100\n",
      "14/14 - 0s - loss: 0.5143 - accuracy: 0.9296 - 72ms/epoch - 5ms/step\n",
      "Epoch 83/100\n",
      "14/14 - 0s - loss: 0.5091 - accuracy: 0.9202 - 79ms/epoch - 6ms/step\n",
      "Epoch 84/100\n",
      "14/14 - 0s - loss: 0.4829 - accuracy: 0.9296 - 73ms/epoch - 5ms/step\n",
      "Epoch 85/100\n",
      "14/14 - 0s - loss: 0.4687 - accuracy: 0.9366 - 67ms/epoch - 5ms/step\n",
      "Epoch 86/100\n",
      "14/14 - 0s - loss: 0.4599 - accuracy: 0.9343 - 64ms/epoch - 5ms/step\n",
      "Epoch 87/100\n",
      "14/14 - 0s - loss: 0.4444 - accuracy: 0.9460 - 61ms/epoch - 4ms/step\n",
      "Epoch 88/100\n",
      "14/14 - 0s - loss: 0.4341 - accuracy: 0.9484 - 59ms/epoch - 4ms/step\n",
      "Epoch 89/100\n",
      "14/14 - 0s - loss: 0.4330 - accuracy: 0.9460 - 58ms/epoch - 4ms/step\n",
      "Epoch 90/100\n",
      "14/14 - 0s - loss: 0.4086 - accuracy: 0.9577 - 59ms/epoch - 4ms/step\n",
      "Epoch 91/100\n",
      "14/14 - 0s - loss: 0.3880 - accuracy: 0.9577 - 57ms/epoch - 4ms/step\n",
      "Epoch 92/100\n",
      "14/14 - 0s - loss: 0.3724 - accuracy: 0.9601 - 62ms/epoch - 4ms/step\n",
      "Epoch 93/100\n",
      "14/14 - 0s - loss: 0.3674 - accuracy: 0.9648 - 57ms/epoch - 4ms/step\n",
      "Epoch 94/100\n",
      "14/14 - 0s - loss: 0.3551 - accuracy: 0.9671 - 59ms/epoch - 4ms/step\n",
      "Epoch 95/100\n",
      "14/14 - 0s - loss: 0.3440 - accuracy: 0.9718 - 55ms/epoch - 4ms/step\n",
      "Epoch 96/100\n",
      "14/14 - 0s - loss: 0.3347 - accuracy: 0.9742 - 60ms/epoch - 4ms/step\n",
      "Epoch 97/100\n",
      "14/14 - 0s - loss: 0.3207 - accuracy: 0.9742 - 65ms/epoch - 5ms/step\n",
      "Epoch 98/100\n",
      "14/14 - 0s - loss: 0.3080 - accuracy: 0.9765 - 68ms/epoch - 5ms/step\n",
      "Epoch 99/100\n",
      "14/14 - 0s - loss: 0.3012 - accuracy: 0.9718 - 78ms/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "14/14 - 0s - loss: 0.2920 - accuracy: 0.9765 - 78ms/epoch - 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f5b5f21d90>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_data_one_hot, y_data_one_hot, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f39beab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, char_to_index, seq_length, seed_text, n):\n",
    "\n",
    "    # 초기 시퀀스\n",
    "    init_text = seed_text\n",
    "    sentence = ''\n",
    "\n",
    "    # 다음 문자 예측은 총 n번만 반복.\n",
    "    for _ in range(n):\n",
    "        encoded = [char_to_index[char] for char in seed_text] # 현재 시퀀스에 대한 정수 인코딩\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, padding='pre') # 데이터에 대한 패딩\n",
    "        encoded = to_categorical(encoded, num_classes=len(char_to_index))\n",
    "\n",
    "        # 입력한 X(현재 시퀀스)에 대해서 y를 예측하고 y(예측한 문자)를 result에 저장.\n",
    "        result = model.predict(encoded, verbose=0)\n",
    "        result = np.argmax(result, axis=1)\n",
    "\n",
    "        for char, index in char_to_index.items():\n",
    "            if index == result:\n",
    "                break\n",
    "\n",
    "        # 현재 시퀀스 + 예측 문자를 현재 시퀀스로 변경\n",
    "        seed_text = seed_text + char\n",
    "\n",
    "        # 예측 문자를 문장에 저장\n",
    "        sentence = sentence + char\n",
    "\n",
    "    # n번의 다음 문자 예측이 끝나면 최종 완성된 문장을 리턴.\n",
    "    sentence = init_text + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0e1cb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I get on with life as a programmer, I like to contemplate beer. But when I stort t ttaende\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, char_to_index, 10, 'I get on w', 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93376f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7e8d84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
